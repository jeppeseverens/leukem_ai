{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cfca22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dir is /Users/jsevere2/Documents/AML_PhD/leukem_ai/out_test/NN/20250623_1622\n",
      "Loading and preparing data\n",
      "\n",
      "\n",
      "  studies_series: 2834\n",
      "  X_df: (60660, 2834)\n",
      "  y_series: 2834\n",
      "  Studies: 2834\n",
      "  X shape: (2834, 60660)\n",
      "  y: 2834\n",
      "\n",
      "\n",
      "  Studies: 2206\n",
      "  X shape: (2206, 60660)\n",
      "  y: 2206\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "#sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "import train_test, transformers, classifiers\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "n_jobs = 1 # Get the value of n_jobs from the parsed arguments\n",
    "# Get the number of inner and outer folds\n",
    "k_out = 2\n",
    "k_in = 2\n",
    "\n",
    "# Get the current date and time in string format\n",
    "time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "model_type = \"NN\"\n",
    "output_dir = f\"/Users/jsevere2/Documents/AML_PhD/leukem_ai/out_test/{model_type}/{time}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Output dir is {output_dir}\")\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"Loading and preparing data\")\n",
    "\n",
    "base_path = \"/Users/jsevere2/Documents/AML_PhD/leukem_ai\"\n",
    "data_path = base_path + \"/data\"\n",
    "\n",
    "X, y, study_labels = train_test.load_data(data_path)\n",
    "X, y, study_labels = train_test.filter_data(X, y, study_labels, min_n = 10)\n",
    "y, label_mapping = train_test.encode_labels(y)\n",
    "\n",
    "# Define the model and parameter grid   \n",
    "if model_type == \"XGBOOST\":\n",
    "    model = classifiers.WeightedXGBClassifier\n",
    "    param_grid = {\n",
    "        'n_genes': [2000, 3000, 5000],\n",
    "        'class_weight': [True],\n",
    "        'max_depth': [2, 3, 5],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'n_estimators': [100, 200],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'gamma': [0, 0.1],\n",
    "        'subsample': [0.8],\n",
    "        'colsample_bytree': [0.8],\n",
    "        'reg_alpha': [0, 0.1],\n",
    "        'reg_lambda': [1.0]\n",
    "    }\n",
    "elif model_type == \"SVM\":\n",
    "    from sklearn.svm import SVC\n",
    "    model = SVC\n",
    "    param_grid = {\n",
    "        'n_genes': [1000, 2000, 3000],\n",
    "        'C': [0.1, 1, 10, 100, 1000],  \n",
    "        'gamma': ['auto', 'scale', 0.0001, 0.001, 0.01, 0.1],  \n",
    "        'class_weight': [\"balanced\", None],\n",
    "        'probability': [True]\n",
    "    }\n",
    "elif model_type == \"NN\":\n",
    "    model = classifiers.NeuralNet\n",
    "    param_grid = {\n",
    "        \"n_genes\": [10000],\n",
    "        \"n_neurons\": [\n",
    "            #[800, 400, 100],\n",
    "            [400, 200, 50],\n",
    "            #[200, 100, 25],\n",
    "            #[800, 400],\n",
    "            #[400, 200],\n",
    "            #[200, 100],\n",
    "            #[100, 50],\n",
    "            \n",
    "        ],\n",
    "        \"use_batch_norm\": [False],\n",
    "        \"dropout_rate\": [0.5],\n",
    "        \"batch_size\": [32],\n",
    "        \"patience\": [1],\n",
    "        \"l2_reg\": [0.001],\n",
    "        \"class_weight\": [True],\n",
    "        \"min_delta\": [0.001],\n",
    "        \"learning_rate\": [0.0001],\n",
    "        \"loss_function\": [\"focal\"],\n",
    "    }\n",
    "else:\n",
    "    raise ValueError(f\"Model type {model_type} not supported\")\n",
    "\n",
    "# If needed downsample param_list\n",
    "full_param_list = list(ParameterGrid(param_grid))\n",
    "\n",
    "# Batch norm and dropout do not play nicely together, waste of compute\n",
    "if model_type == \"NN\":\n",
    "    full_param_list = [\n",
    "        params for params in full_param_list\n",
    "        if not (params['use_batch_norm'] and params['dropout_rate'] > 0)\n",
    "    ]\n",
    "\n",
    "# Downsample if needed\n",
    "n_downsample = 1\n",
    "if len(full_param_list) > n_downsample:\n",
    "    param_list = random.sample(full_param_list, k=n_downsample)\n",
    "else:\n",
    "    param_list = full_param_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6852ee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline set up\n",
      "Starting inner cross-validation process.\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('DEseq2', transformers.DESeq2RatioNormalizer()),\n",
    "    ('feature_selection', transformers.FeatureSelection2()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "print(\"Pipeline set up\")\n",
    "\n",
    "# Start the inner cross-validation process\n",
    "print(\"Starting inner cross-validation process.\")\n",
    "# Iterate through different multiclass classification strategies\n",
    "# standard: Uses the classifier's default multiclass handling\n",
    "# OvO: One-vs-One strategy - trains binary classifier between each pair of classes\n",
    "# OvR: One-vs-Rest strategy - trains binary classifier for each class against all others\n",
    "if model_type == \"NN\":\n",
    "    multi_types = [\"standard\"]\n",
    "else:\n",
    "    multi_types = [\"standard\", \"OvO\", \"OvR\"]\n",
    "\n",
    "multi_types = [\"standard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33fc027b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsevere2/Documents/AML_PhD/leukem_ai/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsevere2/Documents/AML_PhD/leukem_ai/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner_fold\n",
      "0\n",
      "Epoch 1/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0163 - loss: 6.7333 - val_accuracy: 0.0525 - val_loss: 4.1163\n",
      "Epoch 2/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0425 - loss: 5.5716 - val_accuracy: 0.0707 - val_loss: 3.9033\n",
      "Epoch 3/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0478 - loss: 5.1112 - val_accuracy: 0.1105 - val_loss: 3.7639\n",
      "Epoch 4/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0413 - loss: 4.5513 - val_accuracy: 0.1359 - val_loss: 3.6546\n",
      "Epoch 5/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0554 - loss: 5.0359 - val_accuracy: 0.1757 - val_loss: 3.5976\n",
      "Epoch 6/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0736 - loss: 4.4527 - val_accuracy: 0.2246 - val_loss: 3.5296\n",
      "Epoch 7/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0785 - loss: 4.1287 - val_accuracy: 0.2591 - val_loss: 3.4740\n",
      "Epoch 8/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1133 - loss: 3.9839 - val_accuracy: 0.2989 - val_loss: 3.4362\n",
      "Epoch 9/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1227 - loss: 3.7635 - val_accuracy: 0.3351 - val_loss: 3.3923\n",
      "Epoch 10/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0698 - loss: 4.2206 - val_accuracy: 0.3822 - val_loss: 3.3701\n",
      "Epoch 11/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0924 - loss: 3.9268 - val_accuracy: 0.3895 - val_loss: 3.3326\n",
      "Epoch 12/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1176 - loss: 3.9736 - val_accuracy: 0.4221 - val_loss: 3.2936\n",
      "Epoch 13/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1166 - loss: 3.3794 - val_accuracy: 0.4275 - val_loss: 3.2618\n",
      "Epoch 14/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0918 - loss: 3.6313 - val_accuracy: 0.4438 - val_loss: 3.2301\n",
      "Epoch 15/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1310 - loss: 3.6705 - val_accuracy: 0.4565 - val_loss: 3.1861\n",
      "Epoch 16/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2062 - loss: 3.4189 - val_accuracy: 0.4565 - val_loss: 3.1546\n",
      "Epoch 17/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1413 - loss: 3.5394 - val_accuracy: 0.4692 - val_loss: 3.1157\n",
      "Epoch 18/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1935 - loss: 3.3183 - val_accuracy: 0.4946 - val_loss: 3.0749\n",
      "Epoch 19/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1802 - loss: 3.0298 - val_accuracy: 0.5018 - val_loss: 3.0336\n",
      "Epoch 20/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1821 - loss: 3.3043 - val_accuracy: 0.5036 - val_loss: 3.0039\n",
      "Epoch 21/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1582 - loss: 3.6360 - val_accuracy: 0.5109 - val_loss: 2.9752\n",
      "Epoch 22/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2614 - loss: 3.0726 - val_accuracy: 0.5181 - val_loss: 2.9481\n",
      "Epoch 23/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1948 - loss: 3.3925 - val_accuracy: 0.5145 - val_loss: 2.9263\n",
      "Epoch 24/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1975 - loss: 3.1870 - val_accuracy: 0.5181 - val_loss: 2.8997\n",
      "Epoch 25/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2241 - loss: 3.2751 - val_accuracy: 0.5344 - val_loss: 2.8674\n",
      "Epoch 26/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2219 - loss: 3.0880 - val_accuracy: 0.5362 - val_loss: 2.8415\n",
      "Epoch 27/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2441 - loss: 3.0277 - val_accuracy: 0.5525 - val_loss: 2.8276\n",
      "Epoch 28/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2759 - loss: 3.2091 - val_accuracy: 0.5543 - val_loss: 2.7926\n",
      "Epoch 29/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2752 - loss: 3.1521 - val_accuracy: 0.5562 - val_loss: 2.7787\n",
      "Epoch 30/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2521 - loss: 3.0835 - val_accuracy: 0.5598 - val_loss: 2.7496\n",
      "Epoch 31/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2821 - loss: 3.2324 - val_accuracy: 0.5670 - val_loss: 2.7222\n",
      "Epoch 32/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2761 - loss: 3.0909 - val_accuracy: 0.5743 - val_loss: 2.6989\n",
      "Epoch 33/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2822 - loss: 3.4115 - val_accuracy: 0.5688 - val_loss: 2.6733\n",
      "Epoch 34/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3060 - loss: 2.9123 - val_accuracy: 0.5707 - val_loss: 2.6589\n",
      "Epoch 35/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2711 - loss: 3.1436 - val_accuracy: 0.5779 - val_loss: 2.6395\n",
      "Epoch 36/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2888 - loss: 3.0899 - val_accuracy: 0.5851 - val_loss: 2.6107\n",
      "Epoch 37/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3142 - loss: 2.8859 - val_accuracy: 0.5815 - val_loss: 2.5949\n",
      "Epoch 38/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3067 - loss: 2.8085 - val_accuracy: 0.5906 - val_loss: 2.5729\n",
      "Epoch 39/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3490 - loss: 2.9407 - val_accuracy: 0.5960 - val_loss: 2.5591\n",
      "Epoch 40/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3095 - loss: 2.7451 - val_accuracy: 0.5960 - val_loss: 2.5331\n",
      "Epoch 41/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3176 - loss: 2.6821 - val_accuracy: 0.6033 - val_loss: 2.5130\n",
      "Epoch 42/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2999 - loss: 2.9499 - val_accuracy: 0.6214 - val_loss: 2.5145\n",
      "inner_fold\n",
      "1\n",
      "Epoch 1/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0348 - loss: 5.6452 - val_accuracy: 0.0563 - val_loss: 3.9170\n",
      "Epoch 2/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0309 - loss: 4.8213 - val_accuracy: 0.0780 - val_loss: 3.7925\n",
      "Epoch 3/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0393 - loss: 5.0515 - val_accuracy: 0.1234 - val_loss: 3.7163\n",
      "Epoch 4/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0548 - loss: 4.4665 - val_accuracy: 0.1652 - val_loss: 3.6403\n",
      "Epoch 5/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0390 - loss: 4.4232 - val_accuracy: 0.1942 - val_loss: 3.5915\n",
      "Epoch 6/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0635 - loss: 4.5262 - val_accuracy: 0.2123 - val_loss: 3.5581\n",
      "Epoch 7/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0901 - loss: 3.9001 - val_accuracy: 0.2341 - val_loss: 3.5236\n",
      "Epoch 8/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0704 - loss: 4.1568 - val_accuracy: 0.2632 - val_loss: 3.5101\n",
      "Epoch 9/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0929 - loss: 4.7885 - val_accuracy: 0.2831 - val_loss: 3.4801\n",
      "Epoch 10/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0745 - loss: 3.9573 - val_accuracy: 0.3067 - val_loss: 3.4422\n",
      "Epoch 11/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0875 - loss: 3.6717 - val_accuracy: 0.3376 - val_loss: 3.4078\n",
      "Epoch 12/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0955 - loss: 3.6586 - val_accuracy: 0.3539 - val_loss: 3.3821\n",
      "Epoch 13/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1182 - loss: 4.1591 - val_accuracy: 0.3739 - val_loss: 3.3526\n",
      "Epoch 14/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1200 - loss: 3.5093 - val_accuracy: 0.3920 - val_loss: 3.3071\n",
      "Epoch 15/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1658 - loss: 3.8028 - val_accuracy: 0.4083 - val_loss: 3.2716\n",
      "Epoch 16/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1690 - loss: 3.7933 - val_accuracy: 0.4156 - val_loss: 3.2455\n",
      "Epoch 17/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1563 - loss: 3.3616 - val_accuracy: 0.4247 - val_loss: 3.2162\n",
      "Epoch 18/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1203 - loss: 3.5819 - val_accuracy: 0.4356 - val_loss: 3.1911\n",
      "Epoch 19/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1802 - loss: 3.3530 - val_accuracy: 0.4483 - val_loss: 3.1544\n",
      "Epoch 20/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1491 - loss: 3.4882 - val_accuracy: 0.4646 - val_loss: 3.1258\n",
      "Epoch 21/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1435 - loss: 3.5098 - val_accuracy: 0.4828 - val_loss: 3.0877\n",
      "Epoch 22/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1586 - loss: 3.2899 - val_accuracy: 0.4864 - val_loss: 3.0415\n",
      "Epoch 23/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1820 - loss: 3.2081 - val_accuracy: 0.4900 - val_loss: 3.0118\n",
      "Epoch 24/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2218 - loss: 3.3180 - val_accuracy: 0.4828 - val_loss: 2.9971\n",
      "Epoch 25/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1921 - loss: 3.4574 - val_accuracy: 0.4991 - val_loss: 2.9687\n",
      "Epoch 26/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2439 - loss: 3.3226 - val_accuracy: 0.5045 - val_loss: 2.9420\n",
      "Epoch 27/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1976 - loss: 3.2522 - val_accuracy: 0.5009 - val_loss: 2.9221\n",
      "Epoch 28/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2143 - loss: 3.4781 - val_accuracy: 0.4991 - val_loss: 2.9120\n",
      "Epoch 29/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2371 - loss: 3.4401 - val_accuracy: 0.5064 - val_loss: 2.8871\n",
      "Epoch 30/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2232 - loss: 2.8867 - val_accuracy: 0.5100 - val_loss: 2.8590\n",
      "Epoch 31/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2759 - loss: 2.9078 - val_accuracy: 0.5045 - val_loss: 2.8451\n",
      "Epoch 32/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2572 - loss: 3.0171 - val_accuracy: 0.5209 - val_loss: 2.8192\n",
      "Epoch 33/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2328 - loss: 3.2326 - val_accuracy: 0.5336 - val_loss: 2.7988\n",
      "Epoch 34/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2666 - loss: 2.9304 - val_accuracy: 0.5426 - val_loss: 2.7781\n",
      "Epoch 35/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2608 - loss: 3.3407 - val_accuracy: 0.5281 - val_loss: 2.7637\n",
      "Epoch 36/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2365 - loss: 3.1155 - val_accuracy: 0.5263 - val_loss: 2.7546\n",
      "Epoch 37/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2896 - loss: 3.1614 - val_accuracy: 0.5299 - val_loss: 2.7453\n",
      "Epoch 38/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2784 - loss: 2.9328 - val_accuracy: 0.5299 - val_loss: 2.7300\n",
      "Epoch 39/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2755 - loss: 2.8188 - val_accuracy: 0.5354 - val_loss: 2.7006\n",
      "Epoch 40/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2771 - loss: 2.8695 - val_accuracy: 0.5390 - val_loss: 2.6804\n",
      "Epoch 41/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2761 - loss: 3.2100 - val_accuracy: 0.5517 - val_loss: 2.6647\n",
      "Epoch 42/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2415 - loss: 2.8303 - val_accuracy: 0.5463 - val_loss: 2.6607\n",
      "Epoch 43/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2952 - loss: 3.1305 - val_accuracy: 0.5554 - val_loss: 2.6400\n",
      "Epoch 44/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3277 - loss: 2.7869 - val_accuracy: 0.5644 - val_loss: 2.6128\n",
      "Epoch 45/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3008 - loss: 2.5399 - val_accuracy: 0.5590 - val_loss: 2.5945\n",
      "Epoch 46/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2749 - loss: 2.7825 - val_accuracy: 0.5644 - val_loss: 2.5795\n",
      "Epoch 47/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3346 - loss: 2.6315 - val_accuracy: 0.5644 - val_loss: 2.5701\n",
      "Epoch 48/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2883 - loss: 2.5840 - val_accuracy: 0.5644 - val_loss: 2.5409\n",
      "Epoch 49/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3099 - loss: 2.8050 - val_accuracy: 0.5789 - val_loss: 2.5289\n",
      "Epoch 50/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3339 - loss: 2.7208 - val_accuracy: 0.5808 - val_loss: 2.5226\n",
      "Epoch 51/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3358 - loss: 2.5916 - val_accuracy: 0.5880 - val_loss: 2.5152\n",
      "Epoch 52/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3332 - loss: 2.5137 - val_accuracy: 0.5826 - val_loss: 2.5067\n",
      "Epoch 53/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3155 - loss: 2.6210 - val_accuracy: 0.5935 - val_loss: 2.4984\n",
      "Epoch 54/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3167 - loss: 3.0697 - val_accuracy: 0.5880 - val_loss: 2.4961\n",
      "Epoch 55/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3480 - loss: 2.4432 - val_accuracy: 0.5898 - val_loss: 2.4799\n",
      "Epoch 56/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3658 - loss: 2.4340 - val_accuracy: 0.5989 - val_loss: 2.4629\n",
      "Epoch 57/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3864 - loss: 3.0616 - val_accuracy: 0.6025 - val_loss: 2.4505\n",
      "Epoch 58/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3366 - loss: 2.5303 - val_accuracy: 0.6062 - val_loss: 2.4343\n",
      "Epoch 59/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3581 - loss: 2.6894 - val_accuracy: 0.6116 - val_loss: 2.4262\n",
      "Epoch 60/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3427 - loss: 2.7408 - val_accuracy: 0.6098 - val_loss: 2.4159\n",
      "Epoch 61/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3590 - loss: 2.8854 - val_accuracy: 0.6098 - val_loss: 2.4079\n",
      "Epoch 62/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3727 - loss: 2.3450 - val_accuracy: 0.6225 - val_loss: 2.3940\n",
      "Epoch 63/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3743 - loss: 2.6917 - val_accuracy: 0.6207 - val_loss: 2.3793\n",
      "Epoch 64/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3960 - loss: 2.4124 - val_accuracy: 0.6207 - val_loss: 2.3650\n",
      "Epoch 65/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4454 - loss: 2.0521 - val_accuracy: 0.6298 - val_loss: 2.3522\n",
      "Epoch 66/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4053 - loss: 2.3769 - val_accuracy: 0.6407 - val_loss: 2.3466\n",
      "Epoch 67/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4219 - loss: 2.3785 - val_accuracy: 0.6443 - val_loss: 2.3354\n",
      "Epoch 68/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4133 - loss: 2.2297 - val_accuracy: 0.6407 - val_loss: 2.3123\n",
      "Epoch 69/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4429 - loss: 2.1601 - val_accuracy: 0.6370 - val_loss: 2.3203\n",
      "outer_fold\n",
      "1\n",
      "inner_fold\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsevere2/Documents/AML_PhD/leukem_ai/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0334 - loss: 6.2985 - val_accuracy: 0.0833 - val_loss: 3.8778\n",
      "Epoch 2/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0901 - loss: 4.5235 - val_accuracy: 0.1576 - val_loss: 3.6820\n",
      "Epoch 3/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1092 - loss: 4.6340 - val_accuracy: 0.2428 - val_loss: 3.5571\n",
      "Epoch 4/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0926 - loss: 4.4959 - val_accuracy: 0.2627 - val_loss: 3.4757\n",
      "Epoch 5/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1179 - loss: 4.7128 - val_accuracy: 0.3025 - val_loss: 3.3947\n",
      "Epoch 6/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1395 - loss: 4.0033 - val_accuracy: 0.3297 - val_loss: 3.3356\n",
      "Epoch 7/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1224 - loss: 3.8970 - val_accuracy: 0.3967 - val_loss: 3.2784\n",
      "Epoch 8/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1474 - loss: 4.2257 - val_accuracy: 0.4112 - val_loss: 3.2365\n",
      "Epoch 9/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1474 - loss: 4.3605 - val_accuracy: 0.4293 - val_loss: 3.2023\n",
      "Epoch 10/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1524 - loss: 3.6398 - val_accuracy: 0.4293 - val_loss: 3.1716\n",
      "Epoch 11/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1594 - loss: 3.6767 - val_accuracy: 0.4475 - val_loss: 3.1383\n",
      "Epoch 12/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1677 - loss: 4.1351 - val_accuracy: 0.4638 - val_loss: 3.1134\n",
      "Epoch 13/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1978 - loss: 3.7578 - val_accuracy: 0.4511 - val_loss: 3.0771\n",
      "Epoch 14/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2272 - loss: 3.7518 - val_accuracy: 0.4565 - val_loss: 3.0371\n",
      "Epoch 15/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2078 - loss: 3.3710 - val_accuracy: 0.4674 - val_loss: 3.0096\n",
      "Epoch 16/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2134 - loss: 3.3668 - val_accuracy: 0.4746 - val_loss: 2.9721\n",
      "Epoch 17/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2532 - loss: 3.2734 - val_accuracy: 0.4746 - val_loss: 2.9462\n",
      "Epoch 18/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2225 - loss: 3.3760 - val_accuracy: 0.5145 - val_loss: 2.9223\n",
      "Epoch 19/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2423 - loss: 3.6885 - val_accuracy: 0.5127 - val_loss: 2.8983\n",
      "Epoch 20/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1867 - loss: 3.7037 - val_accuracy: 0.5236 - val_loss: 2.8677\n",
      "Epoch 21/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2152 - loss: 3.2388 - val_accuracy: 0.5308 - val_loss: 2.8416\n",
      "Epoch 22/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2187 - loss: 3.9192 - val_accuracy: 0.5326 - val_loss: 2.8361\n",
      "Epoch 23/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2779 - loss: 3.4861 - val_accuracy: 0.5435 - val_loss: 2.8140\n",
      "Epoch 24/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2566 - loss: 3.2280 - val_accuracy: 0.5489 - val_loss: 2.7889\n",
      "Epoch 25/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2514 - loss: 3.1542 - val_accuracy: 0.5525 - val_loss: 2.7670\n",
      "Epoch 26/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2531 - loss: 3.3484 - val_accuracy: 0.5580 - val_loss: 2.7538\n",
      "Epoch 27/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2930 - loss: 3.0795 - val_accuracy: 0.5562 - val_loss: 2.7399\n",
      "Epoch 28/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2770 - loss: 3.3934 - val_accuracy: 0.5562 - val_loss: 2.7158\n",
      "Epoch 29/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2873 - loss: 3.2752 - val_accuracy: 0.5507 - val_loss: 2.7068\n",
      "Epoch 30/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2915 - loss: 3.0843 - val_accuracy: 0.5489 - val_loss: 2.6980\n",
      "Epoch 31/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3276 - loss: 2.9071 - val_accuracy: 0.5471 - val_loss: 2.6744\n",
      "Epoch 32/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3471 - loss: 2.9366 - val_accuracy: 0.5598 - val_loss: 2.6477\n",
      "Epoch 33/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3058 - loss: 2.9833 - val_accuracy: 0.5670 - val_loss: 2.6252\n",
      "Epoch 34/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3323 - loss: 3.1735 - val_accuracy: 0.5761 - val_loss: 2.6037\n",
      "Epoch 35/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3364 - loss: 2.9925 - val_accuracy: 0.5797 - val_loss: 2.5977\n",
      "Epoch 36/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3337 - loss: 2.7086 - val_accuracy: 0.5960 - val_loss: 2.5753\n",
      "Epoch 37/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3143 - loss: 3.1358 - val_accuracy: 0.6014 - val_loss: 2.5599\n",
      "Epoch 38/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3656 - loss: 2.8056 - val_accuracy: 0.5960 - val_loss: 2.5539\n",
      "Epoch 39/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3792 - loss: 2.7229 - val_accuracy: 0.5960 - val_loss: 2.5387\n",
      "Epoch 40/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3830 - loss: 3.0347 - val_accuracy: 0.5870 - val_loss: 2.5369\n",
      "Epoch 41/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3931 - loss: 2.8026 - val_accuracy: 0.5888 - val_loss: 2.5245\n",
      "Epoch 42/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3404 - loss: 3.1216 - val_accuracy: 0.5924 - val_loss: 2.5108\n",
      "Epoch 43/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3541 - loss: 2.8112 - val_accuracy: 0.5924 - val_loss: 2.4916\n",
      "Epoch 44/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3599 - loss: 2.7576 - val_accuracy: 0.5978 - val_loss: 2.4755\n",
      "Epoch 45/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3242 - loss: 2.9896 - val_accuracy: 0.6014 - val_loss: 2.4580\n",
      "Epoch 46/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3663 - loss: 3.3320 - val_accuracy: 0.6159 - val_loss: 2.4488\n",
      "Epoch 47/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3934 - loss: 2.5090 - val_accuracy: 0.6232 - val_loss: 2.4384\n",
      "Epoch 48/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3794 - loss: 2.6281 - val_accuracy: 0.6250 - val_loss: 2.4301\n",
      "Epoch 49/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4227 - loss: 2.4511 - val_accuracy: 0.6141 - val_loss: 2.4191\n",
      "Epoch 50/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3971 - loss: 2.5852 - val_accuracy: 0.6214 - val_loss: 2.3984\n",
      "Epoch 51/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4006 - loss: 2.6152 - val_accuracy: 0.6304 - val_loss: 2.3781\n",
      "Epoch 52/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3872 - loss: 2.6192 - val_accuracy: 0.6395 - val_loss: 2.3587\n",
      "Epoch 53/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3919 - loss: 2.9133 - val_accuracy: 0.6413 - val_loss: 2.3577\n",
      "inner_fold\n",
      "1\n",
      "Epoch 1/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0432 - loss: 5.7587 - val_accuracy: 0.0635 - val_loss: 3.9766\n",
      "Epoch 2/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0597 - loss: 5.5133 - val_accuracy: 0.1180 - val_loss: 3.7344\n",
      "Epoch 3/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0617 - loss: 5.2784 - val_accuracy: 0.1797 - val_loss: 3.5976\n",
      "Epoch 4/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0800 - loss: 4.7694 - val_accuracy: 0.2577 - val_loss: 3.4993\n",
      "Epoch 5/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1236 - loss: 4.2368 - val_accuracy: 0.2995 - val_loss: 3.4359\n",
      "Epoch 6/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0952 - loss: 4.1507 - val_accuracy: 0.3466 - val_loss: 3.3863\n",
      "Epoch 7/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0949 - loss: 4.0583 - val_accuracy: 0.3557 - val_loss: 3.3417\n",
      "Epoch 8/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0911 - loss: 4.1845 - val_accuracy: 0.3848 - val_loss: 3.2980\n",
      "Epoch 9/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1232 - loss: 4.2045 - val_accuracy: 0.4138 - val_loss: 3.2576\n",
      "Epoch 10/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1327 - loss: 3.9193 - val_accuracy: 0.4156 - val_loss: 3.2248\n",
      "Epoch 11/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1362 - loss: 4.1672 - val_accuracy: 0.4319 - val_loss: 3.2021\n",
      "Epoch 12/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1294 - loss: 3.7347 - val_accuracy: 0.4446 - val_loss: 3.1804\n",
      "Epoch 13/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1676 - loss: 3.4277 - val_accuracy: 0.4519 - val_loss: 3.1498\n",
      "Epoch 14/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1797 - loss: 3.6062 - val_accuracy: 0.4574 - val_loss: 3.1208\n",
      "Epoch 15/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1776 - loss: 3.4865 - val_accuracy: 0.4755 - val_loss: 3.0996\n",
      "Epoch 16/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1843 - loss: 3.3985 - val_accuracy: 0.4809 - val_loss: 3.0776\n",
      "Epoch 17/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1973 - loss: 3.2937 - val_accuracy: 0.5027 - val_loss: 3.0493\n",
      "Epoch 18/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1523 - loss: 3.6946 - val_accuracy: 0.5100 - val_loss: 3.0124\n",
      "Epoch 19/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1832 - loss: 3.2466 - val_accuracy: 0.5191 - val_loss: 2.9871\n",
      "Epoch 20/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2738 - loss: 3.3442 - val_accuracy: 0.5209 - val_loss: 2.9657\n",
      "Epoch 21/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2448 - loss: 3.3579 - val_accuracy: 0.5191 - val_loss: 2.9312\n",
      "Epoch 22/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2262 - loss: 3.3506 - val_accuracy: 0.5336 - val_loss: 2.8977\n",
      "Epoch 23/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2358 - loss: 3.2174 - val_accuracy: 0.5426 - val_loss: 2.8672\n",
      "Epoch 24/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2305 - loss: 3.6409 - val_accuracy: 0.5445 - val_loss: 2.8354\n",
      "Epoch 25/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2859 - loss: 3.3911 - val_accuracy: 0.5554 - val_loss: 2.8131\n",
      "Epoch 26/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2782 - loss: 2.9996 - val_accuracy: 0.5499 - val_loss: 2.7876\n",
      "Epoch 27/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2965 - loss: 2.9772 - val_accuracy: 0.5499 - val_loss: 2.7553\n",
      "Epoch 28/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2615 - loss: 3.3135 - val_accuracy: 0.5590 - val_loss: 2.7360\n",
      "Epoch 29/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2901 - loss: 3.1574 - val_accuracy: 0.5735 - val_loss: 2.7136\n",
      "Epoch 30/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2311 - loss: 3.0798 - val_accuracy: 0.5699 - val_loss: 2.6957\n",
      "Epoch 31/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3273 - loss: 3.2118 - val_accuracy: 0.5644 - val_loss: 2.6752\n",
      "Epoch 32/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3115 - loss: 2.9653 - val_accuracy: 0.5826 - val_loss: 2.6663\n",
      "Epoch 33/10000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2972 - loss: 2.9692 - val_accuracy: 0.5735 - val_loss: 2.6709\n",
      "Cross-validation process finished.\n"
     ]
    }
   ],
   "source": [
    "fold_type = \"CV\"\n",
    "if fold_type == \"CV\":\n",
    "    for multi_type in multi_types:\n",
    "        df = train_test.run_inner_cv(\n",
    "            X, y, study_labels, model, param_list, n_jobs, pipe, \n",
    "            multi_type=multi_type, k_out=k_out, k_in=k_in,\n",
    "            model_type = model_type\n",
    "            )\n",
    "        \n",
    "        # Convert encoded labels back to original class names\n",
    "        df = train_test.restore_labels(df, label_mapping)\n",
    "        \n",
    "        # Save results to CSV file with model type, strategy and timestamp\n",
    "        df.to_csv(f\"{output_dir}/{model_type}_inner_cv_{multi_type}_{time}.csv\")   \n",
    "elif fold_type == \"loso\":\n",
    "    for multi_type in multi_types:\n",
    "        df = train_test.run_inner_cv_loso(\n",
    "            X, y, study_labels, model, param_list, n_jobs, pipe, \n",
    "            multi_type=multi_type,\n",
    "            model_type = model_type\n",
    "            )\n",
    "        \n",
    "        # Convert encoded labels back to original class names\n",
    "        df = train_test.restore_labels(df, label_mapping)\n",
    "        \n",
    "        # Save results to CSV file with model type, strategy and timestamp\n",
    "        df.to_csv(f\"{output_dir}/{model_type}_inner_cv_loso_{multi_type}_{time}.csv\")   \n",
    "else:\n",
    "    raise ValueError(f\"Fold type {fold_type} not supported.\")\n",
    "\n",
    "print(\"Cross-validation process finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
